{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afrozmaria07/anomalyDetection-DBSCAN-PID-GAM-PCA/blob/main/Annomaly_Dectection_GAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfxxous2kt7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9565434-ab81-4c09-a983-5cb91cf3e417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting interpret\n",
            "  Downloading interpret-0.6.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting interpret-core==0.6.4 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading interpret_core-0.6.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.10/dist-packages (from interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (1.4.2)\n",
            "Requirement already satisfied: psutil>=5.6.2 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (5.9.5)\n",
            "Collecting shap>=0.28.5 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting dill>=0.2.5 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting SALib>=1.3.3 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading salib-1.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aplr>=10.6.1 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading aplr-10.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (5.5.6)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (7.34.0)\n",
            "Collecting dash>=1.0.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading dash-2.18.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dash-core-components>=1.0.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-html-components>=1.0.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-table>=4.1.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting dash-cytoscape>=0.1.1 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading dash_cytoscape-1.0.2.tar.gz (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gevent>=1.3.6 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading gevent-24.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.32.3)\n",
            "Requirement already satisfied: plotly>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (5.24.1)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (4.12.2)\n",
            "Collecting retrying (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (71.0.4)\n",
            "Collecting zope.event (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting zope.interface (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading zope.interface-7.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (6.3.3)\n",
            "Collecting jedi>=0.16 (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.2->interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.2->interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.2->interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=3.8.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=3.8.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2024.8.30)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.7.1)\n",
            "Collecting multiprocess (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.1->interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (4.66.5)\n",
            "Collecting slicer==0.0.8 (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret)\n",
            "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.2.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (8.1.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.8.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.1.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19.2->interpret-core==0.6.4->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (3.20.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (24.0.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.4->interpret) (4.3.6)\n",
            "Downloading interpret-0.6.4-py3-none-any.whl (1.4 kB)\n",
            "Downloading interpret_core-0.6.4-py3-none-any.whl (14.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aplr-10.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-2.18.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gevent-24.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading salib-1.5.1-py3-none-any.whl (778 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.9/778.9 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading zope.interface-7.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: dash-cytoscape\n",
            "  Building wheel for dash-cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-cytoscape: filename=dash_cytoscape-1.0.2-py3-none-any.whl size=4010717 sha256=03ee5439d0384ff0b327eb6a6dc76e5d520e896f5c2c13e9fbc9d33f8b820c9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/23/5e/56fa701c668444b121ad2353a96478179dc49086a9c44ee930\n",
            "Successfully built dash-cytoscape\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, zope.interface, zope.event, slicer, retrying, jedi, dill, aplr, multiprocess, gevent, shap, SALib, interpret-core, dash, dash-cytoscape, interpret\n",
            "Successfully installed SALib-1.5.1 aplr-10.6.3 dash-2.18.1 dash-core-components-2.0.0 dash-cytoscape-1.0.2 dash-html-components-2.0.0 dash-table-5.0.0 dill-0.3.9 gevent-24.2.1 interpret-0.6.4 interpret-core-0.6.4 jedi-0.19.1 multiprocess-0.70.17 retrying-1.3.4 shap-0.46.0 slicer-0.0.8 zope.event-5.0 zope.interface-7.0.3\n",
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11717 sha256=8ed950b27a37c13f14c8c6256c4c08f4a886cef870cab2e9e15558007e66572a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: liac-arff\n",
            "Successfully installed liac-arff-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install interpret\n",
        "!pip install liac-arff\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import arff\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from interpret.glassbox import ExplainableBoostingClassifier  # GA²M\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ],
      "metadata": {
        "id": "XjVRQzNuozLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Dataset Anomaly'\n",
        "dataset_files = ['/content/drive/MyDrive/Dataset Anomaly/annthyroid.mat', '/content/drive/MyDrive/Dataset Anomaly/ecoli.data', '/content/drive/MyDrive/Dataset Anomaly/cardio.mat','/content/drive/MyDrive/Dataset Anomaly/mulcross.arff','/content/drive/MyDrive/Dataset Anomaly/abalone (2).data']"
      ],
      "metadata": {
        "id": "kovN0fvggxel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path, file_type):\n",
        "    if file_type == \".data\":\n",
        "        df = pd.read_csv(file_path, header=None, sep=',')  # Adjust separator if necessary\n",
        "        # Assuming the last column is the label\n",
        "        X = df.iloc[:, :-1]  # All columns except the last one\n",
        "        y = df.iloc[:, -1]   # The last column as labels\n",
        "        return X, y  # Return both features and labels\n",
        "    elif file_type == \".mat\":\n",
        "        mat_data = loadmat(file_path)\n",
        "        if 'X' in mat_data and 'y' in mat_data:\n",
        "            X = pd.DataFrame(mat_data['X'])\n",
        "            y = pd.Series(mat_data['y'].flatten())  # Convert labels to 1D\n",
        "            return X, y\n",
        "        else:\n",
        "            print(f\"Unexpected structure in {file_path}: {mat_data.keys()}\")\n",
        "            return pd.DataFrame(), pd.Series()  # Return empty DataFrame and Series\n",
        "    elif file_type == \".arff\":\n",
        "        with open(file_path) as f:\n",
        "            arff_data = arff.load(f)\n",
        "        data = np.array(arff_data['data'])\n",
        "        X = pd.DataFrame(data[:, :-1])  # All columns except the last one\n",
        "        y = pd.Series(data[:, -1])       # The last column as labels\n",
        "        return X, y  # Return both features and labels\n",
        "    else:\n",
        "        print(f\"Unsupported file type: {file_type}\")\n",
        "        return pd.DataFrame(), pd.Series()  # Return empty DataFrame and Series\n",
        "\n",
        "# Preprocess Data\n",
        "def preprocess_data(X, y=None):\n",
        "    # Handle non-numeric columns if they exist\n",
        "    for col in X.columns:\n",
        "        if X[col].dtype == 'object':  # Check for non-numeric data\n",
        "            le = LabelEncoder()  # Use label encoding to convert categorical to numeric\n",
        "            X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_imputed = pd.DataFrame(imputer.fit_transform(X))\n",
        "\n",
        "    # Normalize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed))\n",
        "\n",
        "    return X_scaled, y\n",
        "\n",
        "# Load and preprocess all datasets\n",
        "def load_and_preprocess_all_data(folder_path, dataset_files):\n",
        "    combined_X = pd.DataFrame()\n",
        "    combined_y = pd.Series(dtype=np.float64)  # Empty series to store labels\n",
        "\n",
        "    for file in dataset_files:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        file_extension = os.path.splitext(file)[-1]\n",
        "\n",
        "        X, y = load_data(file_path, file_extension)\n",
        "        if not X.empty and not y.empty:  # Check for non-empty DataFrames/Series\n",
        "            X_preprocessed, y_preprocessed = preprocess_data(X, y)\n",
        "            combined_X = pd.concat([combined_X, X_preprocessed], ignore_index=True)\n",
        "            combined_y = pd.concat([combined_y, y_preprocessed], ignore_index=True)\n",
        "        else:\n",
        "            print(f\"Skipped file {file} due to empty data.\")\n",
        "\n",
        "    return combined_X, combined_y\n",
        "\n",
        "# Apply GA²M model (Training Phase)\n",
        "def train_ga2m(X_train, y_train):\n",
        "    model = ExplainableBoostingClassifier()  # GA²M model\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "# Test the model with PID (Testing Phase)\n",
        "def pid_test(model, X_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    # Assuming anomaly detection is based on the prediction of the model\n",
        "    return predictions\n",
        "\n",
        "# Evaluation metrics\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    le = LabelEncoder()\n",
        "    y_true_encoded = le.fit_transform(y_true.astype(str))\n",
        "    y_pred_encoded = le.transform(y_pred.astype(str))\n",
        "\n",
        "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
        "    precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted')\n",
        "    recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted')\n",
        "    f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "bLl4uYQajD6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "5roAGoftjQCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def load_and_preprocess_all_data(folder_path, dataset_files):\n",
        " #   combined_data = pd.DataFrame()\n",
        "\n",
        "  #  for file in dataset_files:\n",
        "   #     file_path = os.path.join(folder_path, file)\n",
        "    #    file_extension = os.path.splitext(file)[-1]\n",
        "\n",
        "     #   df = load_data(file_path, file_extension)\n",
        "      #  if df is not None:\n",
        "       #     df = preprocess_data(df)  # Preprocess the data\n",
        "        #    combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
        "\n",
        "    #return combined_data"
      ],
      "metadata": {
        "id": "YWERWaUdkRBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def train_ga2m(X_train, y_train):\n",
        " #   model = ExplainableBoostingClassifier()  # GA²M model\n",
        "  #  model.fit(X_train, y_train)\n",
        "   # return model"
      ],
      "metadata": {
        "id": "-kkl6TX1kWaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def pid_test(model, X_test):\n",
        " #   predictions = model.predict(X_test)\n",
        "    # Assuming anomaly detection is based on the prediction of the model\n",
        "  #  return predictions"
      ],
      "metadata": {
        "id": "p9QrjcHakcR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def evaluate_model(y_true, y_pred):\n",
        " #   accuracy = accuracy_score(y_true, y_pred)\n",
        "  #  precision = precision_score(y_true, y_pred, average='weighted')\n",
        "   # recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    #f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    #print(f\"Accuracy: {accuracy}\")\n",
        "    #print(f\"Precision: {precision}\")\n",
        "    #print(f\"Recall: {recall}\")\n",
        "    #print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "00VO8HLXkfTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_X, combined_y = load_and_preprocess_all_data(folder_path, dataset_files)\n",
        "\n",
        "# Check the shapes of combined_X and combined_y\n",
        "print(f\"Shape of combined_X: {combined_X.shape}\")\n",
        "print(f\"Shape of combined_y: {combined_y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayqGVhinlx2z",
        "outputId": "93a2b316-21c1-4e48-8264-f7175bb2672a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-358a7931c1b1>:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  combined_y = pd.concat([combined_y, y_preprocessed], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped file /content/drive/MyDrive/Dataset Anomaly/ecoli.data due to empty data.\n",
            "Shape of combined_X: (275352, 21)\n",
            "Shape of combined_y: (275352,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not combined_X.empty and not combined_y.empty:\n",
        "    # Split into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(combined_X, combined_y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train the GA²M model\n",
        "    ga2m_model = train_ga2m(X_train, y_train)\n",
        "\n",
        "    # Apply PID for testing\n",
        "    y_pred = pid_test(ga2m_model, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDPLlncM9vU5",
        "outputId": "62b2895e-03ac-4555-f9f7-0fe882a0a200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/interpret/glassbox/_ebm/_ebm.py:746: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/interpret/glassbox/_ebm/_ebm.py:1014: UserWarning: Detected multiclass problem. Forcing interactions to 0. Multiclass interactions only have local explanations. They are not currently displayed in the global explanation visualizations. Set interactions=0 to disable this warning. If you still want multiclass interactions, this API accepts a list, and the measure_interactions function can be used to detect them.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.dtype)\n",
        "print(y_pred.dtype)\n",
        "print(y_test.unique())\n",
        "print(np.unique(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJGjbwsd_CV4",
        "outputId": "8ca957dc-f992-4cf9-a2f4-4aedbfc7c936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object\n",
            "<U7\n",
            "['Normal' 9 0.0 'Anomaly' 10 7 15 6 12 11 1.0 8 18 20 13 16 19 21 5 17 14\n",
            " 4 3 22 26 23]\n",
            "['0.0' '1.0' '10' '11' '16' '4' '5' '6' '7' '8' '9' 'Anomaly' 'Normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not combined_X.empty and not combined_y.empty:\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(y_test, y_pred)\n",
        "else:\n",
        "    print(\"No data loaded. Please check your data files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5tC_2aTggPF",
        "outputId": "8860bbc6-d481-4bf2-c5bf-878c8adbe422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9874585381207176\n",
            "Precision: 0.9865180538112541\n",
            "Recall: 0.9874585381207176\n",
            "F1 Score: 0.9866645272105448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}